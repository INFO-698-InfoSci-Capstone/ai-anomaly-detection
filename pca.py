# -*- coding: utf-8 -*-
"""PCA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OgWL1Bah1Doly9M6SvFv01iLry6mewhe
"""

import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
import numpy as np

def pca_anomaly_detector(df, numerical_features, categorical_features, variance_retained=0.95, anomaly_percentile=95):
    df = df.copy()

    # Encode categorical features
    for col in categorical_features:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))

    # Combine all features for PCA
    all_features = numerical_features + categorical_features
    X = df[all_features]

    # Standardize the data
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Apply PCA
    pca = PCA(n_components=variance_retained)
    X_pca = pca.fit_transform(X_scaled)

    # Reconstruct the data
    X_reconstructed = pca.inverse_transform(X_pca)

    # Calculate reconstruction error
    reconstruction_error = np.mean((X_scaled - X_reconstructed) ** 2, axis=1)

    # Determine anomaly threshold
    threshold = np.percentile(reconstruction_error, anomaly_percentile)

    # Add results to the DataFrame
    df['pca_anomaly_score'] = reconstruction_error
    df['pca_anomaly_flag'] = (reconstruction_error > threshold).astype(int)

    return df[['pca_anomaly_score', 'pca_anomaly_flag'] + all_features]

code = """
import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
import numpy as np

def pca_anomaly_detector(df, numerical_features, categorical_features, variance_retained=0.95, anomaly_percentile=95):
    df = df.copy()

    # Encode categorical features
    for col in categorical_features:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))

    # Combine all features for PCA
    all_features = numerical_features + categorical_features
    X = df[all_features]

    # Standardize the data
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Apply PCA
    pca = PCA(n_components=variance_retained)
    X_pca = pca.fit_transform(X_scaled)

    # Reconstruct the data
    X_reconstructed = pca.inverse_transform(X_pca)

    # Calculate reconstruction error
    reconstruction_error = np.mean((X_scaled - X_reconstructed) ** 2, axis=1)

    # Determine anomaly threshold
    threshold = np.percentile(reconstruction_error, anomaly_percentile)

    # Add results to the DataFrame
    df['pca_anomaly_score'] = reconstruction_error
    df['pca_anomaly_flag'] = (reconstruction_error > threshold).astype(int)

    return df[['pca_anomaly_score', 'pca_anomaly_flag'] + all_features]
"""

# Write to file
with open("pca_anomaly_detector.py", "w") as f:
    f.write(code)

import pandas as pd

# Step 1: Reload your original dataset
df_raw = pd.read_csv("cyber_threat_logs.csv")

# Step 2: Merge PCA results (make sure order/index matches)
df_raw["pca_anomaly_score"] = df_with_anomalies["pca_anomaly_score"].values
df_raw["pca_anomaly_flag"] = df_with_anomalies["pca_anomaly_flag"].values

# Step 3 (Optional): Filter only anomalies
pca_anomalies_only = df_raw[df_raw["pca_anomaly_flag"] == 1].copy()
pca_anomalies_only["Source"] = "PCA"

# Step 4: Save full merged file
df_raw.to_csv("pca_merged_logs.csv", index=False)
print("✅ Full PCA-merged log data saved as 'pca_merged_logs.csv'")

# (Optional) Save only anomalies separately if needed
pca_anomalies_only.to_csv("pca_anomalies_only.csv", index=False)
print("✅ PCA-only anomalies saved as 'pca_anomalies_only.csv'")